{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T07:18:29.416391Z",
     "iopub.status.busy": "2025-11-21T07:18:29.416073Z",
     "iopub.status.idle": "2025-11-21T07:18:59.407290Z",
     "shell.execute_reply": "2025-11-21T07:18:59.406276Z",
     "shell.execute_reply.started": "2025-11-21T07:18:29.416370Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceLoss\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from skimage import measure\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\" Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\" GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\" GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-21T07:15:29.288894Z",
     "iopub.status.idle": "2025-11-21T07:15:29.289243Z",
     "shell.execute_reply": "2025-11-21T07:15:29.289090Z",
     "shell.execute_reply.started": "2025-11-21T07:15:29.289074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/kaggle/input/brats2020-training-data/BraTS2020_training_data/content/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-21T07:15:29.293715Z",
     "iopub.status.idle": "2025-11-21T07:15:29.294032Z",
     "shell.execute_reply": "2025-11-21T07:15:29.293884Z",
     "shell.execute_reply.started": "2025-11-21T07:15:29.293862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "h5_files = sorted(glob.glob(os.path.join(DATA_PATH, \"*.h5\")))\n",
    "print(f\" Total .h5 files found: {len(h5_files)}\")\n",
    "\n",
    "\n",
    "print(\" First 10 files:\")\n",
    "for i, f in enumerate(h5_files[:10]):\n",
    "    print(f\"  {i+1}. {os.path.basename(f)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T01:37:12.790923Z",
     "iopub.status.busy": "2025-11-21T01:37:12.790162Z",
     "iopub.status.idle": "2025-11-21T01:37:12.819447Z",
     "shell.execute_reply": "2025-11-21T01:37:12.818649Z",
     "shell.execute_reply.started": "2025-11-21T01:37:12.790895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_file = h5_files[100]  # Pick a middle file for variety\n",
    "print(f\" Examining file: {os.path.basename(sample_file)}\")\n",
    "\n",
    "with h5py.File(sample_file, 'r') as f:\n",
    "    # Display all keys stored in the HDF5 file\n",
    "    print(f\" Keys in file: {list(f.keys())}\")\n",
    "    \n",
    "    # Extract image (MRI slice) and segmentation mask\n",
    "    image = f['image'][:]\n",
    "    mask = f['mask'][:]\n",
    "    \n",
    "    print(f\" Image shape: {image.shape}, dtype: {image.dtype}\")\n",
    "    print(f\" Mask shape: {mask.shape}, dtype: {mask.dtype}\")\n",
    "    print(f\" Unique mask values: {np.unique(mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T01:52:01.740863Z",
     "iopub.status.busy": "2025-11-21T01:52:01.740555Z",
     "iopub.status.idle": "2025-11-21T01:52:02.087779Z",
     "shell.execute_reply": "2025-11-21T01:52:02.087058Z",
     "shell.execute_reply.started": "2025-11-21T01:52:01.740832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot MRI image (use first channel if multi-channel)\n",
    "if len(image.shape) == 3:\n",
    "    img_display = image[:, :, 0]\n",
    "else:\n",
    "    img_display = image\n",
    "\n",
    "axes[0].imshow(img_display, cmap='gray')\n",
    "axes[0].set_title('MRI Slice (T1/FLAIR)', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Plot segmentation mask\n",
    "axes[1].imshow(mask, cmap='viridis')\n",
    "axes[1].set_title('Segmentation Mask', fontsize=14)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Overlay mask on MRI for better visualization\n",
    "axes[2].imshow(img_display, cmap='gray')\n",
    "axes[2].imshow(mask, cmap='hot', alpha=0.4)\n",
    "axes[2].set_title('Overlay', fontsize=14)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T01:57:20.199033Z",
     "iopub.status.busy": "2025-11-21T01:57:20.198471Z",
     "iopub.status.idle": "2025-11-21T01:57:20.205916Z",
     "shell.execute_reply": "2025-11-21T01:57:20.205269Z",
     "shell.execute_reply.started": "2025-11-21T01:57:20.199008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BratsSliceDataset(Dataset):   \n",
    "    def __init__(self, file_paths, target_size=(128, 128)):\n",
    "        self.file_paths = file_paths\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        import cv2\n",
    "        \n",
    "        with h5py.File(self.file_paths[idx], 'r') as f:\n",
    "\n",
    "            image = f['image'][:]\n",
    "            mask = f['mask'][:]\n",
    "\n",
    "        if len(image.shape) == 3 and image.shape[2] == 1:\n",
    "             image = np.repeat(image, 4, axis=2) # Duplicate if only 1 channel loaded\n",
    "        elif len(image.shape) == 2:\n",
    "             image = np.expand_dims(image, axis=2)\n",
    "             image = np.repeat(image, 4, axis=2)\n",
    "        \n",
    "        # Resize all 4 channels\n",
    "        resized_channels = []\n",
    "        for i in range(min(4, image.shape[2])): # Ensure we only take up to 4\n",
    "            channel = cv2.resize(image[:, :, i].astype(np.float32), self.target_size, interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            # Z-score Normalization \n",
    "            mean = np.mean(channel)\n",
    "            std = np.std(channel)\n",
    "            if std > 1e-6:\n",
    "                channel = (channel - mean) / std\n",
    "            else:\n",
    "                channel = channel - mean\n",
    "                \n",
    "            resized_channels.append(channel)\n",
    "            \n",
    "        image = np.stack(resized_channels, axis=0) # Shape (4, H, W)\n",
    "        \n",
    "        if len(mask.shape) == 3:\n",
    "            mask = mask[:, :, 0]\n",
    "        \n",
    "        # Resize mask using INTER_NEAREST (critical for preserving labels)\n",
    "        mask = cv2.resize(mask.astype(np.float32), self.target_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        \n",
    "        mask_mapped = np.zeros_like(mask, dtype=np.int64)\n",
    "        mask_mapped[mask == 2] = 1   # Edema\n",
    "        mask_mapped[mask == 1] = 2   # Non-enhancing tumor core\n",
    "        mask_mapped[mask == 4] = 2   # Enhancing tumor\n",
    "        \n",
    "        # Ensure mask is 2D (H, W)\n",
    "        if len(mask_mapped.shape) != 2:\n",
    "            raise ValueError(f\"Mask should be 2D, got shape {mask_mapped.shape}\")\n",
    "        \n",
    "        \n",
    "        # image: (4, H, W), mask: (H, W)\n",
    "        image = torch.from_numpy(image.copy()).float()\n",
    "        mask = torch.from_numpy(mask_mapped.copy()).long()\n",
    "        \n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T01:58:00.661853Z",
     "iopub.status.busy": "2025-11-21T01:58:00.661338Z",
     "iopub.status.idle": "2025-11-21T01:58:00.739980Z",
     "shell.execute_reply": "2025-11-21T01:58:00.739361Z",
     "shell.execute_reply.started": "2025-11-21T01:58:00.661827Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_dataset = BratsSliceDataset(h5_files[:5])\n",
    "sample_img, sample_mask = test_dataset[0]\n",
    "\n",
    "print(f\"   Image tensor shape: {sample_img.shape} -> Expected (1, 128, 128)\")\n",
    "print(f\"   Mask tensor shape: {sample_mask.shape} -> Expected (128, 128)\")\n",
    "print(f\"   Mask unique values: {torch.unique(sample_mask)}\")\n",
    "print(f\"   Mask dtype: {sample_mask.dtype} -> Expected torch.int64\")\n",
    "\n",
    "assert len(sample_mask.shape) == 2, f\"Mask must be 2D! Got {sample_mask.shape}\"\n",
    "\n",
    "\n",
    "train_files, val_files = train_test_split(\n",
    "    h5_files, \n",
    "    test_size=0.1, \n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"   Training samples: {len(train_files)}\")\n",
    "print(f\"   Validation samples: {len(val_files)}\")\n",
    "\n",
    "\n",
    "train_dataset = BratsSliceDataset(train_files)\n",
    "val_dataset = BratsSliceDataset(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T01:58:22.741412Z",
     "iopub.status.busy": "2025-11-21T01:58:22.740662Z",
     "iopub.status.idle": "2025-11-21T01:58:22.747048Z",
     "shell.execute_reply": "2025-11-21T01:58:22.746419Z",
     "shell.execute_reply.started": "2025-11-21T01:58:22.741388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"   Training batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T01:59:31.842860Z",
     "iopub.status.busy": "2025-11-21T01:59:31.842170Z",
     "iopub.status.idle": "2025-11-21T03:16:44.314157Z",
     "shell.execute_reply": "2025-11-21T03:16:44.313123Z",
     "shell.execute_reply.started": "2025-11-21T01:59:31.842834Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128),\n",
    "    strides=(2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\" MONAI U-Net Model Built:\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "\n",
    "# Quick test to verify model output shape\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(1, 1, 128, 128).to(device)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"   Input shape: {test_input.shape}\")\n",
    "    print(f\"   Output shape: {test_output.shape}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8️⃣ Define Loss, Optimizer, Metrics\n",
    "\n",
    "# %%\n",
    "# Loss functions\n",
    "# CrossEntropyLoss expects: pred (B, C, H, W), target (B, H, W)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "# DiceLoss from MONAI expects: pred (B, C, H, W), target (B, 1, H, W)\n",
    "dice_loss = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "\n",
    "def combined_loss(pred, target):\n",
    "\n",
    "    # CrossEntropy: pred (B, 2, H, W), target (B, H, W)\n",
    "    ce = ce_loss(pred, target)\n",
    "    \n",
    "    # Dice: needs target as (B, 1, H, W)\n",
    "    target_dice = target.unsqueeze(1).float()\n",
    "    dice = dice_loss(pred, target_dice)\n",
    "    \n",
    "    return ce + dice\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    ")\n",
    "\n",
    "def compute_dice_score(pred, target, smooth=1e-6):\n",
    "    \"\"\"Compute Dice coefficient for evaluation.\"\"\"\n",
    "    pred_class = torch.argmax(pred, dim=1)\n",
    "    pred_flat = pred_class.view(-1).float()\n",
    "    target_flat = target.view(-1).float()\n",
    "    intersection = (pred_flat * target_flat).sum()\n",
    "    union = pred_flat.sum() + target_flat.sum()\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return dice.item()\n",
    "\n",
    "print(\" Loss, optimizer, and metrics defined!\")\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_dice_scores = []\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Train]\")\n",
    "    \n",
    "    for images, masks in pbar:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = combined_loss(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_train_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    epoch_dice = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS} [Val]\"):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = combined_loss(outputs, masks)\n",
    "            dice = compute_dice_score(outputs, masks)\n",
    "            \n",
    "            epoch_val_loss += loss.item()\n",
    "            epoch_dice += dice\n",
    "    \n",
    "    avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "    avg_dice = epoch_dice / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_dice_scores.append(avg_dice)\n",
    "    \n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    print(f\"\\n Epoch {epoch+1}/{NUM_EPOCHS} Summary:\")\n",
    "    print(f\"   Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"   Val Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"   Val Dice: {avg_dice:.4f}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "print(\"\\n Training Complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T06:41:54.912253Z",
     "iopub.status.busy": "2025-11-21T06:41:54.911523Z",
     "iopub.status.idle": "2025-11-21T06:41:54.922030Z",
     "shell.execute_reply": "2025-11-21T06:41:54.921110Z",
     "shell.execute_reply.started": "2025-11-21T06:41:54.912225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(range(1, NUM_EPOCHS+1), train_losses, 'b-o', label='Train Loss')\n",
    "axes[0].plot(range(1, NUM_EPOCHS+1), val_losses, 'r-o', label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(range(1, NUM_EPOCHS+1), val_dice_scores, 'g-o', label='Val Dice')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Dice Score')\n",
    "axes[1].set_title('Validation Dice Score')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\" Best Val Dice: {max(val_dice_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T06:41:43.057279Z",
     "iopub.status.busy": "2025-11-21T06:41:43.056990Z",
     "iopub.status.idle": "2025-11-21T06:41:43.069214Z",
     "shell.execute_reply": "2025-11-21T06:41:43.068112Z",
     "shell.execute_reply.started": "2025-11-21T06:41:43.057257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_prediction(model, dataset, idx=0):\n",
    "    \"\"\"Visualize model prediction vs ground truth.\"\"\"\n",
    "    model.eval()\n",
    "    image, mask = dataset[idx]\n",
    "    image_batch = image.unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image_batch)\n",
    "        pred = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
    "    \n",
    "    image_np = image.squeeze().cpu().numpy()\n",
    "    mask_np = mask.cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    axes[0].imshow(image_np, cmap='gray')\n",
    "    axes[0].set_title('Input MRI')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(mask_np, cmap='viridis')\n",
    "    axes[1].set_title('Ground Truth')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(pred, cmap='viridis')\n",
    "    axes[2].set_title('Prediction')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    axes[3].imshow(image_np, cmap='gray')\n",
    "    axes[3].imshow(mask_np, cmap='Greens', alpha=0.3)\n",
    "    axes[3].imshow(pred, cmap='Reds', alpha=0.3)\n",
    "    axes[3].set_title('Overlay (Green=GT, Red=Pred)')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "for i in [0, 10, 20]:\n",
    "    if i < len(val_dataset):\n",
    "        fig = visualize_prediction(model, val_dataset, idx=i)\n",
    "        plt.savefig(f'prediction_{i}.png', dpi=150)\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_volume_id(filepath):\n",
    "\n",
    "    basename = os.path.basename(filepath)\n",
    "    parts = basename.replace('.h5', '').split('_')\n",
    "    \n",
    "    vol_id = None\n",
    "    slice_num = None\n",
    "    \n",
    "    for i, part in enumerate(parts):\n",
    "        if part == 'volume' and i+1 < len(parts):\n",
    "            vol_id = parts[i+1]\n",
    "        if part == 'slice' and i+1 < len(parts):\n",
    "            try:\n",
    "                slice_num = int(parts[i+1])\n",
    "            except:\n",
    "                slice_num = 0\n",
    "    \n",
    "    return vol_id, slice_num\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "volume_dict = defaultdict(list)\n",
    "\n",
    "for filepath in h5_files:\n",
    "    vol_id, slice_num = extract_volume_id(filepath)\n",
    "    if vol_id is not None:\n",
    "        volume_dict[vol_id].append((slice_num if slice_num else 0, filepath))\n",
    "\n",
    "# Sort slices within each volume\n",
    "for vol_id in volume_dict:\n",
    "    volume_dict[vol_id].sort(key=lambda x: x[0])\n",
    "\n",
    "print(f\" Found {len(volume_dict)} unique volumes\")\n",
    "print(f\"   Sample volume IDs: {list(volume_dict.keys())[:5]}\")\n",
    "\n",
    "# %%\n",
    "def reconstruct_3d_volume(volume_files, model, device, target_size=(128, 128)):\n",
    "\n",
    "    import cv2\n",
    "    \n",
    "    slices_mri = []\n",
    "    slices_gt = []\n",
    "    slices_pred = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for slice_num, filepath in tqdm(volume_files, desc=\"Loading slices\"):\n",
    "        with h5py.File(filepath, 'r') as f:\n",
    "            image = f['image'][:]\n",
    "            mask = f['mask'][:]\n",
    "        \n",
    "        if len(image.shape) == 3:\n",
    "            image = image[:, :, 0]\n",
    "        \n",
    "        # Resize to match training size\n",
    "        image = cv2.resize(image.astype(np.float32), target_size, interpolation=cv2.INTER_LINEAR)\n",
    "        mask = cv2.resize(mask.astype(np.float32), target_size, interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Normalize\n",
    "        if image.max() > 0:\n",
    "            image = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
    "        \n",
    "        mask = (mask > 0).astype(np.uint8)\n",
    "        \n",
    "        slices_mri.append(image)\n",
    "        slices_gt.append(mask)\n",
    "        \n",
    "        # Get prediction\n",
    "        img_tensor = torch.from_numpy(image.copy()).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(img_tensor)\n",
    "            pred = torch.argmax(output, dim=1).squeeze().cpu().numpy()\n",
    "        slices_pred.append(pred)\n",
    "    \n",
    "    X_3d = np.stack(slices_mri, axis=0)\n",
    "    Y_3d = np.stack(slices_gt, axis=0)\n",
    "    P_3d = np.stack(slices_pred, axis=0)\n",
    "    \n",
    "    return X_3d, Y_3d, P_3d\n",
    "\n",
    "vol_ids = list(volume_dict.keys())\n",
    "selected_vol = vol_ids[0]\n",
    "\n",
    "print(f\" Reconstructing volume: {selected_vol}\")\n",
    "print(f\"   Number of slices: {len(volume_dict[selected_vol])}\")\n",
    "\n",
    "X_3d, Y_3d, P_3d = reconstruct_3d_volume(volume_dict[selected_vol], model, device)\n",
    "\n",
    "print(f\" 3D Volume Shapes:\")\n",
    "print(f\"   MRI: {X_3d.shape}, GT: {Y_3d.shape}, Pred: {P_3d.shape}\")\n",
    "\n",
    "\n",
    "def plot_3d_slices(volume, title=\"3D Volume\"):\n",
    "\n",
    "    z, y, x = volume.shape\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].imshow(volume[z//2, :, :], cmap='gray')\n",
    "    axes[0].set_title(f'{title} - Axial')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(volume[:, y//2, :], cmap='gray')\n",
    "    axes[1].set_title(f'{title} - Coronal')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(volume[:, :, x//2], cmap='gray')\n",
    "    axes[2].set_title(f'{title} - Sagittal')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "plot_3d_slices(X_3d, \"MRI Volume\")\n",
    "plt.savefig('mri_3d_slices.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "plot_3d_slices(Y_3d, \"Ground Truth Tumor\")\n",
    "plt.savefig('gt_tumor_slices.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "plot_3d_slices(P_3d, \"Predicted Tumor\")\n",
    "plt.savefig('pred_tumor_slices.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "def create_3d_mesh(volume, threshold=0.5):\n",
    "\n",
    "    binary_vol = (volume > threshold).astype(np.float32)\n",
    "    \n",
    "    if binary_vol.sum() == 0:\n",
    "        print(\" No tumor voxels found!\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        verts, faces, _, _ = measure.marching_cubes(binary_vol, level=0.5)\n",
    "        print(f\" Mesh: {len(verts)} vertices, {len(faces)} faces\")\n",
    "        return verts, faces\n",
    "    except Exception as e:\n",
    "        print(f\" Error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "gt_verts, gt_faces = create_3d_mesh(Y_3d)\n",
    "pred_verts, pred_faces = create_3d_mesh(P_3d)\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "def plot_3d_mesh(verts, faces, title=\"3D Tumor\", color='red'):\n",
    "\n",
    "    if verts is None:\n",
    "        print(\"No mesh to display\")\n",
    "        return None\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    mesh = Poly3DCollection(verts[faces], alpha=0.7)\n",
    "    mesh.set_facecolor(color)\n",
    "    mesh.set_edgecolor('darkgray')\n",
    "    mesh.set_linewidth(0.1)\n",
    "    \n",
    "    ax.add_collection3d(mesh)\n",
    "    \n",
    "    ax.set_xlim(verts[:, 0].min(), verts[:, 0].max())\n",
    "    ax.set_ylim(verts[:, 1].min(), verts[:, 1].max())\n",
    "    ax.set_zlim(verts[:, 2].min(), verts[:, 2].max())\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "if gt_verts is not None:\n",
    "    fig = plot_3d_mesh(gt_verts, gt_faces, \"Ground Truth Tumor 3D\", 'green')\n",
    "    plt.savefig('gt_tumor_3d.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "if pred_verts is not None:\n",
    "    fig = plot_3d_mesh(pred_verts, pred_faces, \"Predicted Tumor 3D\", 'red')\n",
    "    plt.savefig('pred_tumor_3d.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# Save model weights\n",
    "torch.save(model.state_dict(), 'brats_unet_model.pth')\n",
    "\n",
    "\n",
    "# Save 3D volumes as numpy arrays\n",
    "np.save('mri_volume.npy', X_3d)\n",
    "np.save('gt_mask_volume.npy', Y_3d)\n",
    "np.save('pred_mask_volume.npy', P_3d)\n",
    "print(\" 3D volumes saved as .npy files\")\n",
    "\n",
    "\n",
    "def save_mesh_stl(verts, faces, filename):\n",
    "\n",
    "    try:\n",
    "        from stl import mesh as stl_mesh\n",
    "        \n",
    "        stl_obj = stl_mesh.Mesh(np.zeros(faces.shape[0], dtype=stl_mesh.Mesh.dtype))\n",
    "        for i, f in enumerate(faces):\n",
    "            for j in range(3):\n",
    "                stl_obj.vectors[i][j] = verts[f[j], :]\n",
    "        \n",
    "        stl_obj.save(filename)\n",
    "        print(f\" Saved: {filename}\")\n",
    "    except ImportError:\n",
    "        # Alternative: save as OBJ format\n",
    "        with open(filename.replace('.stl', '.obj'), 'w') as f:\n",
    "            for v in verts:\n",
    "                f.write(f\"v {v[0]} {v[1]} {v[2]}\\n\")\n",
    "            for face in faces:\n",
    "                f.write(f\"f {face[0]+1} {face[1]+1} {face[2]+1}\\n\")\n",
    "        print(f\" Saved as OBJ: {filename.replace('.stl', '.obj')}\")\n",
    "\n",
    "if gt_verts is not None:\n",
    "    save_mesh_stl(gt_verts, gt_faces, 'gt_tumor.stl')\n",
    "    \n",
    "if pred_verts is not None:\n",
    "    save_mesh_stl(pred_verts, pred_faces, 'pred_tumor.stl')\n",
    "\n",
    "\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"\\n Output Files:\")\n",
    "print(\"   • brats_unet_model.pth - Trained model weights\")\n",
    "print(\"   • training_curves.png - Loss/Dice plots\")\n",
    "print(\"   • prediction_*.png - Sample predictions\")\n",
    "print(\"   • *_3d_slices.png - Orthogonal views\")\n",
    "print(\"   • *_tumor_3d.png - 3D visualizations\")\n",
    "print(\"   • *.npy - 3D volume arrays\")\n",
    "print(\"   • *.stl/*.obj - 3D mesh files\")\n",
    "print(f\"\\n Final Validation Dice Score: {max(val_dice_scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 723383,
     "sourceId": 1267593,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
